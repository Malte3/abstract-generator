{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"GQ18Kd5F3uKe"},"outputs":[],"source":["!pip install -q tika\n","\n","!pip install -q summa"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"yGdQ2xGe1Dd4"},"outputs":[],"source":["import urllib.request\n","import lxml.etree as etree\n","import tika\n","from tika import parser\n","import csv\n","import os\n","import re\n","import shutil\n","import torch\n","\n","import torchtext\n","from torchtext.data.utils import get_tokenizer, RandomShuffler\n","from torchtext.data.dataset import check_split_ratio, rationed_split, stratify\n","from summa import summarizer\n","\n","tika.initVM()\n","\n","class PaperAbstractDataset(torchtext.data.Dataset):\n","    \"\"\"Defines a dataset composed of Examples along with its Fields, for paper and abstracts.\n","    \"\"\"\n","    sort_key = None\n","\n","    @classmethod\n","    def splits(cls, search_query = 'all', max_results = 300, start = 0, reduced_words=1000, savepath='data',  split_ratio=0.7, stratified=False, strata_field='abstract',\n","              random_state=None, **kwargs):\n","        \"\"\"Create Dataset objects for multiple splits of a dataset.\n","\n","        Arguments:\n","            search_query (str): specify searchh query for arxiv, default is 'all' results, more information on ttps://arxiv.org/help/api.\n","            max_results (int): maxium search results from arxiv from search query\n","            savepath (str): save path for the txt files\n","            split_ratio (float or List of floats): a number [0, 1] denoting the amount\n","                of data to be used for the training split (rest is used for validation),\n","                or a list of numbers denoting the relative sizes of train, test and valid\n","                splits respectively. If the relative size for valid is missing, only the\n","                train-test split is returned. Default is 0.7 (for the train set).\n","            stratified (bool): whether the sampling should be stratified.\n","                Default is False.\n","            strata_field (str): name of the examples Field stratified over.\n","                Default is 'label' for the conventional label field.\n","            random_state (tuple): the random seed used for shuffling.\n","                A return value of `random.getstate()`.\n","\n","        Returns:\n","            Tuple[Dataset]: Datasets for train, validation, and\n","            test splits in that order, if provided.\n","        \"\"\"\n","\n","         # initialize text filed\n","        text_field = torchtext.data.Field(tokenize=get_tokenizer(\"spacy\"), init_token='<sos>', eos_token='<eos>', lower=True)\n","        fields = [('abstract', text_field), ('paper', text_field)]\n","        examples = []\n","\n","        # Create new dataset by downloading from arxiv or open dataset from folder\n","        if not os.path.exists(savepath):\n","            os.mkdir(savepath)\n","            # create directories for saving the data set\n","            if not os.path.exists(os.path.join(savepath, 'temp')):\n","                os.mkdir(os.path.join(savepath, 'temp'))\n","            if not os.path.exists(os.path.join(savepath, 'abstracts')):\n","                os.mkdir(os.path.join(savepath, 'abstracts'))\n","            if not os.path.exists(os.path.join(savepath, 'paper')):\n","                os.mkdir(os.path.join(savepath, 'paper'))\n","            data = cls.download(search_query=search_query, max_results=max_results)\n","            abstracts, papers = cls.extract_paper_and_abstract(data, savepath=savepath)\n","\n","            # generate all examples\n","            for i, (abstract, paper) in enumerate(zip(abstracts, papers)):\n","                paper_tokenized = []\n","                abstract_tokenized = []\n","                # rdeduce the number of words with the textrank approach\n","                textranked_paper = summarizer.summarize(paper, words=reduced_words)\n","                # add start and end token\n","                paper_tokenized += [u'<sos>'] + text_field.preprocess(textranked_paper) + [u'<eos>']\n","                abstract_tokenized += [u'<sos>'] + text_field.preprocess(abstract) + [u'<eos>']\n","                # initialize examples\n","                examples.append(torchtext.data.Example.fromlist([abstract_tokenized, paper_tokenized], fields))\n","\n","                # save data samples in txt files\n","                with open(os.path.join(savepath,'abstracts','abstract_' + str(i) + '.txt'), 'w+', encoding='utf-8') as abstr:\n","                    csvwriter = csv.writer(abstr, delimiter=' ')\n","                    csvwriter.writerow(abstract_tokenized)\n","                with open(os.path.join(savepath,'paper','paper_' + str(i) + '.txt'), 'w+', encoding='utf-8') as pap:\n","                    csvwriter = csv.writer(pap, delimiter=' ')\n","                    csvwriter.writerow(paper_tokenized)\n","\n","        else:\n","            # read all files in saved data path\n","            paper_files = os.listdir(os.path.join(savepath,'paper'))\n","            abstract_files = os.listdir(os.path.join(savepath,'abstracts'))\n","            data = [[paper, abstract] for paper, abstract in zip(paper_files, abstract_files)]\n","            papers_tokenized = []\n","            abstracts_tokenized = []\n","            # read paper and abstracts from files\n","            for paper, abstract in data:\n","                with open(os.path.join(savepath, 'paper', paper), encoding='utf-8') as csvfile:\n","                    paper = csv.reader(csvfile, delimiter=' ')\n","                    for pap in paper:\n","                        if pap:\n","                            papers_tokenized.append(pap)\n","                with open(os.path.join(savepath, 'abstracts', abstract), encoding='utf-8') as csvfile:\n","                    abstract = csv.reader(csvfile, delimiter=' ')\n","                    for abstr in abstract:\n","                        if abstr:\n","                            abstracts_tokenized.append(abstr)\n","       \n","            # generate all examples\n","            for abstract_tokenized, paper_tokenized in zip(abstracts_tokenized, papers_tokenized):\n","                examples.append(torchtext.data.Example.fromlist([abstract_tokenized, paper_tokenized], fields))\n","\n","        # create initial dataset\n","        dataset = PaperAbstractDataset(examples, fields)\n","        # split dataset\n","        splits = dataset.split(split_ratio=split_ratio, stratified=stratified, strata_field=strata_field,\n","              random_state=random_state)\n","        # initialize vocabulary\n","        pre_trained_vector_type = 'glove.6B.300d'\n","        for d in splits:\n","            for name, field in d.fields.items():\n","                field.build_vocab(splits[0], vectors=pre_trained_vector_type)\n","            d.filter_examples(['abstract', 'paper'])\n","        return splits\n","\n","    @classmethod\n","    def download(cls, search_query = 'all', max_results = 300, start = 0):\n","        '''\n","            Download e-prints from https://arxiv.org with arXiv API\n","            search_query (str): specify searchh query for arxiv, default is 'all' results, more information on ttps://arxiv.org/help/api.\n","            max_results (int): maxium search results from arxiv from search query\n","        '''\n","        url = 'http://export.arxiv.org/api/query?search_query=' + search_query + '&start=' + str(start) + '&max_results=' + str(max_results)\n","        data = urllib.request.urlopen(url).read()\n","        return data\n","\n","    @classmethod\n","    def extract_paper_and_abstract(cls, data, savepath='.'):\n","        '''\n","            Extract the abstracts from the xml search query response and download the pdf paper and extract the plain text from it and remove possible abstract in there\n","\n","            data (str): xml data with all paper urls and abstracts\n","            savepath (str): save path for the txt files\n","        '''\n","        # build xml tree\n","        root = etree.fromstring(data)\n","        # reserve lists\n","        abstracts = []\n","        papers = []\n","        # extract abstract directly from summary tag and extract pdf url\n","        for child in root:\n","            if len(child) > 0 and child.tag == '{http://www.w3.org/2005/Atom}entry':\n","                for grandchild in child:\n","                    if grandchild.tag == '{http://www.w3.org/2005/Atom}summary':\n","                            abstracts.append(grandchild.text)\n","                    if grandchild.tag == '{http://www.w3.org/2005/Atom}link' and 'title' in grandchild.attrib and grandchild.attrib['title'] == 'pdf':\n","                            papers.append(grandchild.attrib['href'])\n","        \n","        ## download pdfs, extract plain text, remove possible abstracts in there\n","        for i, paper in enumerate(papers):\n","            # download pdf\n","            pdf = urllib.request.urlopen(paper).read()\n","            # save pdf temporarily as file\n","            filename = paper.split('/')[-1]\n","            with open(os.path.join(savepath,'temp', filename + '.pdf'), 'wb+') as f:\n","                    f.write(pdf)\n","            # parse pdf file to get psdf text content and replace url with text content\n","            parsed = parser.from_file(os.path.join(savepath,'temp', filename + '.pdf'))['content']\n","            # remove line breaks with hyphenation in paper and abstract\n","            hyph_norm_parsed_paper = re.sub('-\\n', '', parsed)\n","            abstract_rgex_pattern = re.sub('-\\n', '', abstracts[i])\n","            # make list of words from abstract\n","            abstract_words = abstract_rgex_pattern.split()\n","            # remove abstract by searching for paragraph starting with abstract and ending with double whitespace\n","            parsed = re.sub('(?i)(\\s*)(abstract)([\\s\\S]' + '{0,' + str(len(abstract_rgex_pattern)*4//3) + '})' + re.escape(abstract_rgex_pattern[-3:-1]) + '\\s\\s', '\\n', hyph_norm_parsed_paper)\n","            # remove abstract by searching for paragraph start and end of abstract\n","            parsed = re.sub('(?i)(\\s*)' + re.escape(abstract_rgex_pattern[0:3]) + '([\\s\\S]' + '{0,' + str(len(abstract_rgex_pattern)*4//3) + '})' + re.escape(abstract_rgex_pattern[-3:-1]) , '\\n', parsed)\n","            # remove abstract by searching for paragraph start word and end word of abstract\n","            parsed = re.sub('(?i)(\\s*)' + re.escape(abstract_words[0]) + '([\\s\\S]' + '{0,' + str(len(abstract_rgex_pattern)*4//3) + '})' + re.escape(abstract_words[-1]), '\\n', parsed)\n","            # remove abstract heading in case it was not found before\n","            parsed = re.sub('(?i)(\\s*)(abstract)', '\\n', parsed)\n","            # remove unnecessary whitespace\n","            abstracts[i] = ' '.join(abstract_words)\n","            parsed = ' '.join(parsed.split())\n","            papers[i] = parsed\n","\n","        # remove temporary pdfs\n","        shutil.rmtree(os.path.join(savepath,'temp'))\n","        return abstracts, papers"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":1642734,"status":"ok","timestamp":1574506903498,"user":{"displayName":"Malte Rethwisch","photoUrl":"","userId":"01059676619809927561"},"user_tz":-60},"id":"nKe7tIDo1gr9","outputId":"2d3a9af7-fb52-42d5-d562-4f7afc14a669"},"outputs":[{"name":"stderr","output_type":"stream","text":["2019-11-23 10:34:40,603 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.22/tika-server-1.22.jar to /tmp/tika-server.jar.\n","2019-11-23 10:34:48,292 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.22/tika-server-1.22.jar.md5 to /tmp/tika-server.jar.md5.\n","2019-11-23 10:34:48,924 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                           \n","100%|█████████▉| 399170/400000 [01:01<00:00, 8446.54it/s]"]},{"name":"stdout","output_type":"stream","text":["0m 4s (- 18m 13s) (0 0%) 25.0816\n","0m 8s (- 17m 42s) (1 0%) 80.2051\n","0m 12s (- 17m 37s) (2 0%) 169.6711\n","0m 17s (- 17m 38s) (3 1%) 122.1138\n","0m 21s (- 17m 40s) (4 1%) 216.5567\n","0m 25s (- 17m 27s) (5 2%) 156.9093\n","0m 29s (- 17m 19s) (6 2%) 186.3907\n","0m 34s (- 17m 17s) (7 2%) 180.2817\n","0m 38s (- 17m 12s) (8 3%) 205.7474\n","0m 42s (- 17m 11s) (9 3%) 204.8943\n","0m 47s (- 17m 4s) (10 4%) 272.9036\n","0m 51s (- 17m 5s) (11 4%) 282.6956\n","0m 55s (- 16m 59s) (12 4%) 271.9934\n","1m 0s (- 16m 57s) (13 5%) 255.9083\n","1m 4s (- 16m 46s) (14 5%) 224.7135\n","1m 8s (- 16m 40s) (15 6%) 290.8861\n","1m 13s (- 16m 40s) (16 6%) 356.1182\n","1m 17s (- 16m 38s) (17 6%) 289.3171\n","1m 22s (- 16m 37s) (18 7%) 303.3049\n","1m 26s (- 16m 32s) (19 7%) 268.0943\n","1m 31s (- 16m 32s) (20 8%) 255.6070\n","1m 35s (- 16m 30s) (21 8%) 219.3561\n","1m 39s (- 16m 24s) (22 8%) 405.8056\n","1m 44s (- 16m 21s) (23 9%) 403.7109\n","1m 48s (- 16m 17s) (24 9%) 395.5891\n","1m 52s (- 16m 12s) (25 10%) 480.9748\n","1m 57s (- 16m 7s) (26 10%) 434.6777\n","2m 1s (- 16m 1s) (27 10%) 391.9973\n","2m 5s (- 15m 55s) (28 11%) 362.1831\n","2m 9s (- 15m 52s) (29 11%) 346.6015\n","2m 14s (- 15m 48s) (30 12%) 333.8445\n","2m 18s (- 15m 44s) (31 12%) 353.1145\n","2m 22s (- 15m 40s) (32 12%) 436.7753\n","2m 27s (- 15m 35s) (33 13%) 328.9852\n","2m 31s (- 15m 32s) (34 13%) 414.2863\n","2m 35s (- 15m 26s) (35 14%) 387.8683\n","2m 40s (- 15m 22s) (36 14%) 455.6812\n","2m 44s (- 15m 19s) (37 14%) 391.7537\n","2m 49s (- 15m 16s) (38 15%) 336.9704\n","2m 53s (- 15m 11s) (39 15%) 294.8209\n","2m 57s (- 15m 5s) (40 16%) 277.1047\n","3m 1s (- 15m 0s) (41 16%) 314.6101\n","3m 6s (- 14m 58s) (42 16%) 362.1644\n","3m 10s (- 14m 54s) (43 17%) 353.5518\n","3m 15s (- 14m 50s) (44 17%) 304.1130\n","3m 19s (- 14m 46s) (45 18%) 343.3484\n","3m 24s (- 14m 43s) (46 18%) 420.7136\n","3m 28s (- 14m 39s) (47 18%) 407.4595\n","3m 33s (- 14m 34s) (48 19%) 382.9201\n","3m 37s (- 14m 29s) (49 19%) 415.7575\n","3m 42s (- 14m 26s) (50 20%) 410.8803\n","3m 46s (- 14m 22s) (51 20%) 465.6949\n","3m 50s (- 14m 17s) (52 20%) 409.1372\n","3m 54s (- 14m 12s) (53 21%) 391.8480\n","3m 58s (- 14m 6s) (54 21%) 341.0388\n","4m 3s (- 14m 2s) (55 22%) 326.8690\n","4m 7s (- 13m 58s) (56 22%) 278.8775\n","4m 11s (- 13m 53s) (57 22%) 381.0520\n","4m 15s (- 13m 48s) (58 23%) 371.2792\n","4m 20s (- 13m 44s) (59 23%) 328.8174\n","4m 24s (- 13m 40s) (60 24%) 342.8856\n","4m 28s (- 13m 35s) (61 24%) 322.0059\n","4m 32s (- 13m 30s) (62 24%) 354.8697\n","4m 37s (- 13m 25s) (63 25%) 359.1847\n","4m 41s (- 13m 21s) (64 25%) 336.6968\n","4m 46s (- 13m 17s) (65 26%) 355.3106\n","4m 50s (- 13m 12s) (66 26%) 386.4851\n","4m 54s (- 13m 7s) (67 26%) 376.4277\n","4m 59s (- 13m 4s) (68 27%) 353.2685\n","5m 3s (- 13m 0s) (69 27%) 396.1236\n","5m 7s (- 12m 55s) (70 28%) 433.4375\n","5m 11s (- 12m 51s) (71 28%) 374.2264\n","5m 16s (- 12m 46s) (72 28%) 350.1336\n","5m 20s (- 12m 43s) (73 29%) 364.8556\n","5m 25s (- 12m 38s) (74 29%) 368.2506\n","5m 29s (- 12m 34s) (75 30%) 381.1618\n","5m 34s (- 12m 30s) (76 30%) 401.6968\n","5m 38s (- 12m 26s) (77 30%) 429.2178\n","5m 42s (- 12m 22s) (78 31%) 469.2221\n","5m 47s (- 12m 17s) (79 31%) 453.3411\n","5m 51s (- 12m 13s) (80 32%) 459.2910\n","5m 56s (- 12m 9s) (81 32%) 488.6168\n","6m 0s (- 12m 5s) (82 32%) 500.6270\n","6m 4s (- 12m 0s) (83 33%) 480.3821\n","6m 8s (- 11m 55s) (84 33%) 468.0111\n","6m 13s (- 11m 51s) (85 34%) 400.6185\n","6m 17s (- 11m 47s) (86 34%) 414.2687\n","6m 22s (- 11m 43s) (87 34%) 397.8520\n","6m 26s (- 11m 38s) (88 35%) 416.2344\n","6m 30s (- 11m 34s) (89 35%) 412.4631\n","6m 35s (- 11m 30s) (90 36%) 399.5352\n","6m 39s (- 11m 25s) (91 36%) 600.1932\n","6m 43s (- 11m 21s) (92 36%) 509.4686\n","6m 47s (- 11m 16s) (93 37%) 467.9548\n","6m 52s (- 11m 12s) (94 37%) 433.7314\n","6m 56s (- 11m 7s) (95 38%) 565.9835\n","7m 0s (- 11m 3s) (96 38%) 539.2934\n","7m 4s (- 10m 58s) (97 38%) 462.7048\n","7m 9s (- 10m 54s) (98 39%) 471.2447\n","7m 13s (- 10m 50s) (99 39%) 440.9144\n","7m 17s (- 10m 45s) (100 40%) 457.1387\n","7m 22s (- 10m 41s) (101 40%) 433.2178\n","7m 26s (- 10m 37s) (102 40%) 455.5837\n","7m 31s (- 10m 33s) (103 41%) 468.8537\n","7m 35s (- 10m 28s) (104 41%) 510.9495\n","7m 39s (- 10m 24s) (105 42%) 485.5076\n","7m 44s (- 10m 20s) (106 42%) 433.3556\n","7m 48s (- 10m 16s) (107 42%) 439.6835\n","7m 52s (- 10m 11s) (108 43%) 474.6270\n","7m 57s (- 10m 7s) (109 43%) 451.4487\n","8m 0s (- 10m 2s) (110 44%) 530.1880\n","8m 5s (- 9m 58s) (111 44%) 533.2821\n","8m 10s (- 9m 54s) (112 44%) 519.6244\n","8m 14s (- 9m 49s) (113 45%) 579.0052\n","8m 18s (- 9m 45s) (114 45%) 606.7999\n","8m 23s (- 9m 41s) (115 46%) 598.8258\n","8m 27s (- 9m 37s) (116 46%) 594.5528\n","8m 31s (- 9m 32s) (117 46%) 544.7155\n","8m 35s (- 9m 27s) (118 47%) 531.2421\n","8m 40s (- 9m 23s) (119 47%) 487.2623\n","8m 44s (- 9m 19s) (120 48%) 462.9216\n","8m 49s (- 9m 15s) (121 48%) 539.5335\n","8m 53s (- 9m 10s) (122 48%) 507.6045\n","8m 57s (- 9m 6s) (123 49%) 450.9624\n","9m 1s (- 9m 1s) (124 49%) 396.5928\n","9m 6s (- 8m 57s) (125 50%) 326.6799\n","9m 10s (- 8m 53s) (126 50%) 377.5938\n","9m 14s (- 8m 48s) (127 50%) 420.4301\n","9m 19s (- 8m 44s) (128 51%) 422.7119\n","9m 23s (- 8m 40s) (129 51%) 481.0484\n","9m 28s (- 8m 36s) (130 52%) 492.9225\n","9m 32s (- 8m 31s) (131 52%) 472.7437\n","9m 36s (- 8m 27s) (132 52%) 470.7648\n","9m 41s (- 8m 23s) (133 53%) 520.1639\n","9m 45s (- 8m 18s) (134 53%) 521.1133\n","9m 49s (- 8m 14s) (135 54%) 474.1629\n","9m 54s (- 8m 9s) (136 54%) 457.4828\n","9m 58s (- 8m 5s) (137 54%) 539.1784\n","10m 2s (- 8m 1s) (138 55%) 535.1328\n","10m 6s (- 7m 56s) (139 55%) 597.1546\n","10m 11s (- 7m 52s) (140 56%) 558.2288\n","10m 15s (- 7m 48s) (141 56%) 529.7746\n","10m 20s (- 7m 43s) (142 56%) 526.9372\n","10m 24s (- 7m 39s) (143 57%) 467.9592\n","10m 28s (- 7m 35s) (144 57%) 478.7838\n","10m 32s (- 7m 30s) (145 57%) 486.6582\n","10m 37s (- 7m 26s) (146 58%) 435.5417\n","10m 41s (- 7m 21s) (147 58%) 455.0328\n","10m 45s (- 7m 17s) (148 59%) 482.9962\n","10m 50s (- 7m 13s) (149 59%) 467.8700\n","10m 54s (- 7m 9s) (150 60%) 469.4765\n","10m 58s (- 7m 4s) (151 60%) 551.5903\n","11m 2s (- 7m 0s) (152 60%) 546.2704\n","11m 7s (- 6m 55s) (153 61%) 494.8561\n","11m 11s (- 6m 51s) (154 61%) 494.9870\n","11m 16s (- 6m 47s) (155 62%) 438.8618\n","11m 20s (- 6m 42s) (156 62%) 444.0224\n","11m 24s (- 6m 38s) (157 62%) 510.6529\n","11m 29s (- 6m 34s) (158 63%) 499.1417\n","11m 33s (- 6m 30s) (159 63%) 461.2670\n","11m 37s (- 6m 25s) (160 64%) 517.5948\n","11m 41s (- 6m 21s) (161 64%) 561.4052\n","11m 45s (- 6m 16s) (162 64%) 548.9671\n","11m 50s (- 6m 12s) (163 65%) 494.9718\n","11m 54s (- 6m 8s) (164 65%) 452.7592\n","11m 58s (- 6m 3s) (165 66%) 480.2058\n","12m 2s (- 5m 59s) (166 66%) 423.2393\n","12m 7s (- 5m 54s) (167 66%) 417.4219\n","12m 11s (- 5m 50s) (168 67%) 461.0038\n","12m 16s (- 5m 46s) (169 67%) 481.7528\n","12m 20s (- 5m 42s) (170 68%) 483.0519\n","12m 25s (- 5m 37s) (171 68%) 540.2966\n","12m 29s (- 5m 33s) (172 68%) 514.2429\n","12m 33s (- 5m 29s) (173 69%) 496.0025\n","12m 37s (- 5m 24s) (174 69%) 549.9199\n","12m 42s (- 5m 20s) (175 70%) 531.7712\n","12m 46s (- 5m 16s) (176 70%) 520.5467\n","12m 51s (- 5m 11s) (177 70%) 512.4717\n","12m 55s (- 5m 7s) (178 71%) 539.4287\n","12m 59s (- 5m 3s) (179 71%) 502.3351\n","13m 3s (- 4m 58s) (180 72%) 528.7638\n","13m 8s (- 4m 54s) (181 72%) 642.3330\n","13m 12s (- 4m 50s) (182 72%) 642.6189\n","13m 16s (- 4m 45s) (183 73%) 597.9347\n","13m 21s (- 4m 41s) (184 73%) 627.0223\n","13m 25s (- 4m 37s) (185 74%) 564.7099\n","13m 29s (- 4m 32s) (186 74%) 562.8673\n","13m 33s (- 4m 28s) (187 74%) 538.9725\n","13m 37s (- 4m 23s) (188 75%) 493.1780\n","13m 42s (- 4m 19s) (189 75%) 537.6122\n","13m 46s (- 4m 15s) (190 76%) 543.0622\n","13m 50s (- 4m 11s) (191 76%) 529.9153\n","13m 55s (- 4m 6s) (192 76%) 524.8063\n","13m 59s (- 4m 2s) (193 77%) 558.0957\n","14m 3s (- 3m 58s) (194 77%) 532.8104\n","14m 7s (- 3m 53s) (195 78%) 487.2256\n","14m 12s (- 3m 49s) (196 78%) 552.4073\n","14m 16s (- 3m 44s) (197 78%) 541.6653\n","14m 21s (- 3m 40s) (198 79%) 509.7896\n","14m 25s (- 3m 36s) (199 79%) 554.6665\n","14m 29s (- 3m 32s) (200 80%) 530.9932\n","14m 33s (- 3m 27s) (201 80%) 498.0612\n","14m 38s (- 3m 23s) (202 80%) 500.0421\n","14m 42s (- 3m 19s) (203 81%) 476.8951\n","14m 47s (- 3m 14s) (204 81%) 489.6599\n","14m 51s (- 3m 10s) (205 82%) 515.0712\n","14m 55s (- 3m 6s) (206 82%) 577.1900\n","15m 0s (- 3m 1s) (207 82%) 653.1149\n","15m 4s (- 2m 57s) (208 83%) 650.9552\n","15m 9s (- 2m 53s) (209 83%) 625.4660\n","15m 13s (- 2m 48s) (210 84%) 608.4295\n","15m 17s (- 2m 44s) (211 84%) 568.5479\n","15m 22s (- 2m 40s) (212 84%) 481.4484\n","15m 26s (- 2m 35s) (213 85%) 445.0076\n","15m 30s (- 2m 31s) (214 85%) 445.6316\n","15m 34s (- 2m 27s) (215 86%) 446.4396\n","15m 39s (- 2m 22s) (216 86%) 434.0408\n","15m 43s (- 2m 18s) (217 86%) 413.9600\n","15m 48s (- 2m 14s) (218 87%) 368.7315\n","15m 52s (- 2m 9s) (219 87%) 388.3840\n","15m 57s (- 2m 5s) (220 88%) 443.4862\n","16m 1s (- 2m 1s) (221 88%) 457.3887\n","16m 5s (- 1m 56s) (222 88%) 486.1507\n","16m 9s (- 1m 52s) (223 89%) 410.4881\n","16m 13s (- 1m 48s) (224 89%) 406.0766\n","16m 18s (- 1m 43s) (225 90%) 466.9361\n","16m 22s (- 1m 39s) (226 90%) 490.2565\n","16m 26s (- 1m 35s) (227 90%) 565.4061\n","16m 31s (- 1m 30s) (228 91%) 552.9901\n","16m 35s (- 1m 26s) (229 91%) 566.5652\n","16m 40s (- 1m 22s) (230 92%) 546.8887\n","16m 44s (- 1m 17s) (231 92%) 509.6287\n","16m 48s (- 1m 13s) (232 92%) 516.5736\n","16m 53s (- 1m 9s) (233 93%) 460.5397\n","16m 57s (- 1m 4s) (234 93%) 442.7457\n","17m 1s (- 1m 0s) (235 94%) 435.6098\n","17m 5s (- 0m 56s) (236 94%) 551.1061\n","17m 10s (- 0m 51s) (237 94%) 510.7600\n","17m 14s (- 0m 47s) (238 95%) 503.8248\n","17m 19s (- 0m 43s) (239 95%) 533.6262\n","17m 23s (- 0m 38s) (240 96%) 476.6799\n","17m 27s (- 0m 34s) (241 96%) 460.8714\n","17m 32s (- 0m 30s) (242 96%) 472.3539\n","17m 36s (- 0m 25s) (243 97%) 485.4644\n","17m 40s (- 0m 21s) (244 97%) 585.7360\n","17m 44s (- 0m 17s) (245 98%) 517.9833\n","17m 49s (- 0m 12s) (246 98%) 469.0844\n","17m 53s (- 0m 8s) (247 98%) 419.2836\n","17m 58s (- 0m 4s) (248 99%) 474.0387\n","18m 2s (- 0m 0s) (249 99%) 464.4686\n","> [', a higher - , has been in [ 22 ] , which is shown that have with more number of than a single . some such as one - to - all and all - to - all are and in . in one - to - all , a a to every other in the . whereas , in all - to - all , every is as a and its to every other in the . in this paper , an one - to - all in higher is . the paper shows that the a number of to the . in , the are to be - , the all - to - all is into three . the are and that the one - to - all than the - one - to - all and has number of']\n","= ['4.1 one - to - all the and the one - to - all have the same number of and , which is where m is the of the and n is the number of . \\n in , all 11 4 all - to - all 1 : , minor , , x , y , , phase ) 2 : let n be the number of and m be the of the 3 : if > and phase = 3 then 4 : 5 : if > and phase < 3 then 6 : all - to - , 1 , ) 7 : 8 : if x > 0 then 9 : via minor ( , minor , , 1 , 0 , 1 , phase ) 10 : if y > 0 then 11 : via ( , minor , , 1 , y − 1 , 1 , phase ) : if > 1 then : all - to - 1 , , 14 : phase ) open the other three and them to the from their the ( , −1 , and + ) . \\n then , the number of in each for the is 14 1 : an of the ( ) one - to - all on ( 3 ) 3 + free 1 1 1 6 7 2 6 18 3 18 2 1 2 3 3 1 2 3 and as : = ( 5 ) where r is the number such that 0 ≤ r < n and d is the or number r such that 1 ≤ d ≤ m . \\n 1 the number of free , , , and in each in the ( 3 ) 3 + for the one - to - all . \\n 2 the number of free , , , and in each of the applied on the ( 3 ) 3 + . \\n figure the number of free in each of the in ( 3 ) 3 + . \\n from and 18 , it can be that the in the is between the and in the 18 0 1 2 3 4 5 6 7 8 9 n m b o f n o d figure : one - to - all : number of free in each in ( 3 ) 3 + . \\n 0 1 2 3 4 5 6 7 8 9 n m b o f n o d figure 18 : one - to - all : number of in each in ( 3 ) 3 + .']\n","< ['\\\\sigma 10 karlin interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval']\n","\n","> [', a higher - , has been in [ 22 ] , which is shown that have with more number of than a single . some such as one - to - all and all - to - all are and in . in one - to - all , a a to every other in the . whereas , in all - to - all , every is as a and its to every other in the . in this paper , an one - to - all in higher is . the paper shows that the a number of to the . in , the are to be - , the all - to - all is into three . the are and that the one - to - all than the - one - to - all and has number of']\n","= ['4.1 one - to - all the and the one - to - all have the same number of and , which is where m is the of the and n is the number of . \\n in , all 11 4 all - to - all 1 : , minor , , x , y , , phase ) 2 : let n be the number of and m be the of the 3 : if > and phase = 3 then 4 : 5 : if > and phase < 3 then 6 : all - to - , 1 , ) 7 : 8 : if x > 0 then 9 : via minor ( , minor , , 1 , 0 , 1 , phase ) 10 : if y > 0 then 11 : via ( , minor , , 1 , y − 1 , 1 , phase ) : if > 1 then : all - to - 1 , , 14 : phase ) open the other three and them to the from their the ( , −1 , and + ) . \\n then , the number of in each for the is 14 1 : an of the ( ) one - to - all on ( 3 ) 3 + free 1 1 1 6 7 2 6 18 3 18 2 1 2 3 3 1 2 3 and as : = ( 5 ) where r is the number such that 0 ≤ r < n and d is the or number r such that 1 ≤ d ≤ m . \\n 1 the number of free , , , and in each in the ( 3 ) 3 + for the one - to - all . \\n 2 the number of free , , , and in each of the applied on the ( 3 ) 3 + . \\n figure the number of free in each of the in ( 3 ) 3 + . \\n from and 18 , it can be that the in the is between the and in the 18 0 1 2 3 4 5 6 7 8 9 n m b o f n o d figure : one - to - all : number of free in each in ( 3 ) 3 + . \\n 0 1 2 3 4 5 6 7 8 9 n m b o f n o d figure 18 : one - to - all : number of in each in ( 3 ) 3 + .']\n","< ['\\\\sigma 10 karlin interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval interval']\n","\n","Error in callback <function install_repl_displayhook.<locals>.post_execute at 0x7f589b2aa8c8> (for post_execute):\n"]},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mpost_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mpost_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mdraw_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# IPython >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/_pylab_helpers.py\u001b[0m in \u001b[0;36mdraw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf_mgr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1905\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1906\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1907\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_cursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1709\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m   1205\u001b[0m                                                                 renderer)\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mticks\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdrawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \"\"\"\n\u001b[0;32m-> 1079\u001b[0;31m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m         \u001b[0mmajor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0mmajor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;34m\"\"\"Get the array of major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1797\u001b[0m         \u001b[0;34m'Return the locations of the ticks'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1799\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   1806\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvmax\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvmin\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.001\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmin\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1808\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_if_exceeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1810\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mview_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mraise_if_exceeds\u001b[0;34m(self, locs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m             raise RuntimeError(\"Locator attempting to generate {} ticks from \"\n\u001b[1;32m   1519\u001b[0m                                \"{} to {}: exceeds Locator.MAXTICKS\".format(\n\u001b[0;32m-> 1520\u001b[0;31m                                    len(locs), locs[0], locs[-1]))\n\u001b[0m\u001b[1;32m   1521\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Locator attempting to generate 2783 ticks from -25.2 to 531.1999999999999: exceeds Locator.MAXTICKS"]}],"source":["import time\n","import math\n","import torch\n","import torchtext\n","import random\n","import os\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","# initialize random seed so the train, evaluation and test split stay the same\n","random.seed(42)\n","\n","# Do computations on gpu if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Dataset inherited from torchtext.data.Dataset either creates data by downloading from arxiv, 500 is maximum ofd samples and the number of words needs to be reduced to fit inside the memory\n","train_data, val_data = PaperAbstractDataset.splits(max_results=5, reduced_words=500, random_state=random.getstate())\n","\n","# Initialize Interator for the data with batch size\n","batch_size = 1\n","train_iter, val_iter = torchtext.data.BucketIterator.splits(\n","                        (train_data, val_data), batch_sizes=(batch_size, batch_size),\n","                        device=device, \n","                        sort_key=lambda x: len(x.paper),\n","                        shuffle=True, sort_within_batch=False, repeat=False)\n","# Put paper and abstract (source, target) in one batch tuple\n","class BatchTuple():\n","    def __init__(self, dataset, x_var, y_var):\n","        self.dataset, self.x_var, self.y_var = dataset, x_var, y_var\n","        \n","    def __iter__(self):\n","        for batch in self.dataset:\n","            x = getattr(batch, self.x_var) \n","            y = getattr(batch, self.y_var)                 \n","            yield (x, y)\n","            \n","    def __len__(self):\n","        return len(self.dataset)\n","\n","train_iter_tuple = BatchTuple(train_iter, \"abstract\", \"paper\")\n","val_iter_tuple = BatchTuple(val_iter, \"abstract\", \"paper\")\n","\n","# put out one example batch tuple\n","next(iter(train_iter_tuple))\n","\n","# compute maximal paper length\n","MAX_LENGTH = 0\n","for abstract, paper in train_iter_tuple:\n","    if len(paper) > MAX_LENGTH:\n","        MAX_LENGTH = len(paper)\n","for abstract, paper in val_iter_tuple:\n","    if len(paper) > MAX_LENGTH:\n","        MAX_LENGTH = len(paper)\n","\n","# The encoder and decoder model from NLP From Scratch: Translation with a Sequence to Sequence Network and Attention (https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html), chosen because of its simplicity\n","class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, hidden = self.gru(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n","\n","# Normal Decoder\n","class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden):\n","        output = self.embedding(input).view(1, 1, -1)\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","        output = self.softmax(self.out(output[0]))\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n","\n","# Attention Decoder\n","class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n","\n","teacher_forcing_ratio = 0.5\n","\n","# The training process is also from NLP From Scratch: Translation with a Sequence to Sequence Network and Attention (https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        decoder_input = target_tensor[0]\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n","\n","def trainIters(encoder, decoder, epochs, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    criterion = nn.NLLLoss()\n","    for epoch in range(epochs):\n","        for target, source in train_iter_tuple:\n","            input_tensor = source\n","            target_tensor = target\n","\n","            loss = train(input_tensor, target_tensor, encoder,\n","                        decoder, encoder_optimizer, decoder_optimizer, criterion)\n","            print_loss_total += loss\n","            plot_loss_total += loss\n","\n","        if epoch % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, (epoch+1) / epochs),\n","                                        epoch, epoch / epochs * 100, print_loss_avg))\n","\n","        if epoch % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = sentence\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = sentence[0]  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, max_length)\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            decoder_attentions[di] = decoder_attention.data\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == train_data.fields['paper'].eos_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                if topi.item() != train_data.fields['paper'].pad_token:\n","                    decoded_words.append(topi.item())\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return torch.tensor(decoded_words, dtype=torch.int32).unsqueeze(-1), decoder_attentions[:di + 1]\n","\n","def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)\n","\n","# function to make words from numericalized text adapted from torchtext ReverseField\n","def reverse(field, batch):\n","        if not field.batch_first:\n","            batch = batch.t()\n","        with torch.cuda.device_of(batch):\n","            batch = batch.tolist()\n","        batch = [[field.vocab.itos[ind] for ind in ex] for ex in batch]  # denumericalize\n","\n","        def trim(s, t):\n","            sentence = []\n","            for w in s:\n","                if w == t:\n","                    break\n","                sentence.append(w)\n","            return sentence\n","\n","        batch = [trim(ex, field.eos_token) for ex in batch]  # trim past frst eos\n","\n","        def filter_special(tok):\n","            return tok not in (field.init_token, field.pad_token)\n","\n","        batch = [filter(filter_special, ex) for ex in batch]\n","        return [' '.join(ex) for ex in batch]\n","\n","def evaluateRandomly(encoder, decoder, n=2):\n","    for i in range(n):\n","        pair = next(iter(val_iter_tuple))\n","        print('>', reverse(train_data.fields['paper'], pair[0]))\n","        print('=', reverse(train_data.fields['paper'], pair[1]))\n","        output_words, attentions = evaluate(encoder, decoder, pair[1])\n","        output_sentence = reverse(train_data.fields['paper'], output_words)\n","        print('<', output_sentence)\n","        print('')\n","\n","# Initialize Network and Parameters\n","hidden_size = 256\n","ntokens = len(next(iter(train_data.fields.values())).vocab.stoi) \n","encoder1 = EncoderRNN(ntokens, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, ntokens, dropout_p=0.1).to(device)\n","\n","# Train new parameters or load them from previous trainings, if you want to restart training delte or rename old .pth files \n","if os.path.exists('encoder.pth') and os.path.exists('decoder.pth'):\n","    encoder1.load_state_dict(torch.load('encoder.pth'))\n","    attn_decoder1.load_state_dict(torch.load('decoder.pth'))\n","else:\n","    trainIters(encoder1, attn_decoder1, 250, print_every=1)\n","    torch.save(encoder1.state_dict(), 'encoder.pth')\n","    torch.save(attn_decoder1.state_dict(), 'decoder.pth')\n","\n","# Show some randomly chosen evaluations\n","evaluateRandomly(encoder1, attn_decoder1)\n"]},{"cell_type":"code","execution_count":0,"metadata":{"colab":{},"colab_type":"code","id":"1IyPsf3yjNBZ"},"outputs":[],"source":["#!rm -rf /content/data"]}]}